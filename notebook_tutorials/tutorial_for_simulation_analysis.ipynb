{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bcd88d",
   "metadata": {},
   "source": [
    "### Processing and analyzing images\n",
    "This notebook highlights some basic essentials with processing and analyzing simulated images. We'll use the output data file included with degrad tools to demonstrate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm #progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "'''Setting up some rcparameters for better size axis labels'''\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('xtick', labelsize=14)\n",
    "plt.rc('ytick', labelsize=14)\n",
    "plt.rc('axes', labelsize=16)\n",
    "plt.rc('axes', titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"data/4.975keV_1000Events_all.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27decb3",
   "metadata": {},
   "source": [
    "### Descriptions of each column (for people who use ROOT you'll hear columns being called \"branches\") in our dataframe:\n",
    "\n",
    "-**nHits**: Number of primary electron tracks in the simulation\n",
    "\n",
    "-**x**, **y**, **z**: Primary track x, y, and z coordinates\n",
    "\n",
    "-**t**: Relative time of ionization deposit. (x,y,z) are sorted in time-order\n",
    "\n",
    "-**flag**: Not so important. Flag indicates the physical process with which the ionization electron was generated: 1=fluorescence; 2=pair production; 3=bremsstrahlung; 0=otherwise\n",
    "\n",
    "-**truth_dir**: (x,y,z) unit vector of ER\n",
    "\n",
    "-**truth_energy**: Energy of the primary track\n",
    "\n",
    "-**ionization_energy**: ionization energy in CF4 of the primary track. This is computed as 'nHits' x W where W = 34.2 eV\n",
    "\n",
    "-**truth_theta**: truth zenith angle (w.r.t z-axis) determined by 'truth_dir'\n",
    "\n",
    "-**truth_phi**: truth aximuthal angle (in xy plane w.r.t +x) determined by 'truth_dir'\n",
    "\n",
    "-**drift_length**: Amount of drift simulated. Currently using a random-uniform distribution between 1cm and 2.5cm. TODO for Jeff: Make this adjustable in configuration.yaml\n",
    "\n",
    "-**xdiff**, **ydiff**, **zdiff**: x,y, and z coordinates of ionization after applying diffusion over 'drift_length'\n",
    "\n",
    "-**xamp**, **yamp**, **zamp**: The electrons from (xdiff,ydiff,zdiff) that align with the openings of a GEM hole\n",
    "\n",
    "-**xcam**, **ycam**, **qcam**: (x,y) after applying gain and diffusion through the transfer gap, binned to the 2048 x 1152 camera dimensions. 'qcam' is the number of amplified electrons falling into the bin\n",
    "\n",
    "-**xITO**, **zITO**, **qITO**: (x,z) after applying gain and diffusion through the transfer gap, *and induction gap* binned to 120 strips along x. z is quantified assuming 0.26um per bin. 'qITO' is the number of amplified electrons falling into the ITO bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ec97c",
   "metadata": {},
   "source": [
    "### A couple of very useful pandas operations for this kind of data\n",
    "1. Pandas supports lambda expressions which are vectorized and therefore much faster than running nested loops\n",
    "over the dataframe\n",
    "\n",
    "2. Pandas has lots of flexibility to query data for cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3237cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: truth_dir is a 3-vector, let's find the magnitude of 'truth_dir' in all entries in df \n",
    "# (it should be 1 of course)\n",
    "df['truth_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e65918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a lambda expression to compute the magnintude\n",
    "\n",
    "df['truth_dir'].apply(lambda x: np.sqrt(x[0]**2 + x[1]**2 + x[2]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda expressions apply a function elementwise. We can use numpy functions or user defined functions\n",
    "\n",
    "df['truth_dir'].apply(lambda x: np.linalg.norm(x)) #same thing as the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853535a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['truth_theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Querying data\n",
    "\n",
    "df.query('cos(truth_theta)>0') #finds all entries with cos(theta) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36233655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean expressions are supported with & for 'and' and | for 'or'\n",
    "# each clause needs to have parenthesis surrounding it when using boolean expressions\n",
    "# pandas also allows inequalities like a < qty <= b\n",
    "\n",
    "#Example: ionization energ y> 5.9 keV and phi in [-pi/2,pi/2]\n",
    "df.query('(ionization_energy > 5.9) & (-%s/2 <= truth_phi <= %s/2)'%(np.pi,np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3: making cuts based on lambda expressions\n",
    "'''query() expressions are nice (and I use them all the time) but they are somewhat limited.\n",
    "Here\"s an example where we select all events with summed charge greater than a certain threshold'''\n",
    "\n",
    "print(f\"Raw charges:\\n{df['qcam']}\\n\") #charge\n",
    "\n",
    "print(f\"Summed charges:\\n{df['qcam'].apply(lambda x: x.sum())}\\n\") #summed charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe11523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's select all events with the summed charge over a certain threshold\n",
    "threshold = 1.5e6\n",
    "\n",
    "df[df['qcam'].apply(lambda x: x.sum()) > threshold] #here's the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also define new columns freely in our dataframe\n",
    "\n",
    "df['qSum'] = df['qcam'].apply(lambda x: x.sum())\n",
    "print(df['qSum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836bc08",
   "metadata": {},
   "source": [
    "### Processing_images\n",
    "\n",
    "Binned images are stored in \"sparse\" format as opposed to \"dense\" format. Sparse data includes (x,y,z,...) coordinate info for pixels > threshold value (we use 0 here). This means we ignore all 0's in our image.\n",
    "This is computationally and storage efficient, as most of our image is empty (i.e. 0).\n",
    "\n",
    "A 2048 x 1152 image of 16 bit pixels is 2048 x 1152 x 16 bits x 1 byte / 8 bits = 4.7 MB\n",
    "\n",
    "On average, each image has around 7,000 non-zero pixels, so storing the image in sparse format gives:\\\n",
    "**2** & 7000 & 16 bits * 1byte / 8 bits = 28 kB **factor of 160 reduction over dense**\n",
    "\n",
    "The bolded **2** comes from the fact that we're looking at x-y images, so we have 7000 16-bit integers for x and an additional 7000 16-bit integers for y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77b91b",
   "metadata": {},
   "source": [
    "### Making images dense requires us binning them.\n",
    "**It's actually computationally faster to bin sparse coordinates so sparsity helps us in many ways**\n",
    "\n",
    "We'll be using [numpy's histogram2d function for this](https://numpy.org/doc/stable/reference/generated/numpy.histogram2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sparse coordinates to dense coordinates. Use np.histogram2d\n",
    "\n",
    "eventnum = 0 #let's look at event number 0\n",
    "\n",
    "event = df.iloc[eventnum] #grab the event\n",
    "\n",
    "#Declaring each argument for clarity. Native bin size is (2048,1152). xcam, and ycam\n",
    "#are already binned to 0-2047 and 0-1151, respectively\n",
    "#The function reference shows that argument 0 of the function is the 2D histogram (ndarray)\n",
    "\n",
    "im = np.histogram2d(x=event['xcam'],y=event['ycam'],weights=event['qcam'],\n",
    "                   bins=(2048,1152),range=((0,2048),(0,1152)))[0].T #transpose makes x and y as they should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(im) #image shape is what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colormap reference https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "\n",
    "#Our group uses 'jet' for historical reasons. We really should use a perceptually uniform sequential\n",
    "#colormap like 'viridis' or 'plasma'\n",
    "plt.imshow(im,cmap='jet')\n",
    "plt.xlim(event['xcam'].min()-10,event['xcam'].max()+10)\n",
    "plt.ylim(event['ycam'].min()-10,event['ycam'].max()+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lets make a function to efficiently bin images'''\n",
    "\n",
    "#bin_factor is the factor we downsample the image by. For example\n",
    "#bin_factor = 4 is 4x4 binning\n",
    "def create_image(x,y,q,bin_factor):\n",
    "    im = np.histogram2d(x=x,y=y,weights=q,\n",
    "                   bins=(2048//bin_factor,1152//bin_factor),\n",
    "                        range=((0,2048),(0,1152)))[0].T #transpose makes x and y as they should be\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629c00e",
   "metadata": {},
   "source": [
    "### Slick way to use lambda expressions to create images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''Create 4x4-binned images for all tracks'''\n",
    "tqdm.pandas() #for progressbar\n",
    "\n",
    "#axis = 1 for row-wise operations over the dataframe\n",
    "ims = df.progress_apply(lambda row: create_image(row['xcam'],row['ycam'],row['qcam'],bin_factor = 4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742751a",
   "metadata": {},
   "source": [
    "### More syntactically clear way to create images\n",
    "**Choose either this way or the way above to make your images but not both. Memory can fill up very quickly storing too many images**\n",
    "\n",
    "As a note: I use the \"htop\" command in my terminal to check my memory and cpu usage. I do this very regularly to check if there's any computation I'm performing that uses too much memory (sometimes recasting array's as 32-bit or 16-bit datatypes can really help mitigate memory at the expense of precision). Mac users can install htop with homebrew (*brew install htop*), linux users can use the package manager for their distro, for windows...I dunno, I'm pretty sure there's a system performance monitor you can pull up with ctrl + alt + del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5baaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''Create 4x4-binned images for all tracks but easier to read'''\n",
    "ims2 = [] #will be the same as ims above but we'll do it with a for loop\n",
    "for i in tqdm(range(0,len(df))):\n",
    "    tmp = df.iloc[i] #grab ith entry\n",
    "    ims2.append(create_image(tmp['xcam'],tmp['ycam'],tmp['qcam'],bin_factor = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6359514",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sanity check that ims and ims2 are the same'''\n",
    "np.abs((np.array(ims.to_list())-np.array(ims2))).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97648f98",
   "metadata": {},
   "source": [
    "### One other note: This is *not* recommended but you could always add the dense images to your pandas dataframe with df['ims'] = ims or something similar. Generally speaking, it's better to just work with the sparse images and create dense images when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadf6b0",
   "metadata": {},
   "source": [
    "### Now let's plot our images with their corresponding keypoints on top of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c14216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_truth(event_num,bin_fact,zoom = True):\n",
    "    tmp = df.iloc[event_num]\n",
    "    '''Plot image'''\n",
    "    im = create_image(tmp['xcam'],tmp['ycam'],tmp['qcam'],bin_factor=bin_fact) #use our create_image function\n",
    "    plt.imshow(im,cmap='jet')\n",
    "    #plt.imshow(ims[event_num],cmap='jet')\n",
    "    '''make colorbar for image'''\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('Intensity')\n",
    "    '''plot truth'''\n",
    "    scale_factor = (2048//bin_fact)/8 #conversion factor between cm and pixels. Camera pixels are squares\n",
    "    '''Primary tracks are centered so we need to shift them in binned coordinates to the center'''\n",
    "    shiftx = 2048//bin_fact/2\n",
    "    shifty = 1152//bin_fact/2 #ylength is 1152 pixels\n",
    "    plt.plot(tmp['x']*scale_factor+shiftx,tmp['y']*scale_factor+shifty,'o',color='k',markersize=2)\n",
    "    '''Labels'''\n",
    "    plt.xlabel('x [pixels]')\n",
    "    plt.ylabel('y [pixels]')\n",
    "    if zoom:\n",
    "        plt.xlim((tmp['xcam']//bin_fact).min()-5,(tmp['xcam']//bin_fact).max()+5)\n",
    "        plt.ylim((tmp['ycam']//bin_fact).min()-5,(tmp['ycam']//bin_fact).max()+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2f185",
   "metadata": {},
   "source": [
    "### Plot several images with keypoints on top of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b265982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,24))\n",
    "for i in range(1,9):\n",
    "    plt.subplot(4,2,i)\n",
    "    plot_with_truth(event_num = 0, bin_fact = i, zoom = True)\n",
    "    plt.title('%s x %s binning'%(i,i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5d698",
   "metadata": {},
   "source": [
    "### Now we have a sense of how to bin images. Next steps are seeing if we can create images with corresponding text files for keypoints. \n",
    "\n",
    "We're using [Ultralytics' YOLOv8 package](https://github.com/ultralytics/ultralytics) to train our models. For keypoint detection we use the YOLOv8-pose family of models. The train/validation/test dataset format guide can be found here: https://docs.ultralytics.com/datasets/pose/\n",
    "\n",
    "The relevant part for us is that our datalabel format will be a textfile formatted like this:\n",
    "\n",
    "[**class-index**] [**x**] [**y**] [**width**] [**height**] [**px1**] [**py1**] [**px2**] [**py2**] ... [**pxn**] [**pyn**]\n",
    "    \n",
    "where\n",
    "\n",
    "**class_index**: Integer index for the class of track in the data. If we had a mixed dataset with ERs, NRs, protons, etc. we would use different values for each class. Here we have just ERs, so we can use 0 as the value for class index\n",
    "\n",
    "**x**: The x-coordinate center of the bounding box of the track-image\n",
    "\n",
    "**y**: The y-coordinate center of the bounding box of the track-image\n",
    "\n",
    "**width**: Width of the bounding box\n",
    "\n",
    "**height**: Height of the bounding box\n",
    "\n",
    "**pxj**: x-coordinate of the jth truth keypoint (truth ionization electron)\n",
    "\n",
    "**pyj**: y-coordinate of the jth truth keypoint (truth ionization electron)\n",
    "\n",
    "### Some additional notes\n",
    "\n",
    "1. In this sample all images have one track. This the label text file corresponding to each will include only a single line with these quantities\n",
    "\n",
    "2. We want the quantities in our label file to be **scale invariant**. What I usually do is define each coordinate as a fraction of the pixel dimension of the image. For example pixel (842,921) on the image would be stored as (842/2048 , 921 / 1152) [because the image dimensions are (2048,1152)]\n",
    "\n",
    "3. Since we know the truth boundary of the simulated tracks, it shouldn't be too difficult to generate accurate bounding boxes\n",
    "\n",
    "4. **What we ultimately want is each of these 1000 images saved as a png in a folder called images/ and then an associated labels text file for each image in a folder called labels/**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
